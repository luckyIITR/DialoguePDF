{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9a03f933-87ec-46ea-9fdf-96ab2ac3730c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from time import time\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5ad79cb-6195-42f0-99da-1c3795d77743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "# os.getenv(\"access_token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef7b58f2-8365-4d63-bf8a-b1c2d86f3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # set quantization configuration to load large model with less GPU memory\n",
    "# # this requires the `bitsandbytes` library\n",
    "# bnb_config = transformers.BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_quant_type='nf4',\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "#     bnb_4bit_compute_dtype=bfloat16\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89b3fef3-bd66-4d36-961b-faf272191193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-2-7b-chat-hf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "75340720-6e44-4449-90c7-79e70db1584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = transformers.AutoConfig.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9744aa85-53cd-4466-b3ab-2853e58af0b3",
   "metadata": {},
   "source": [
    "## Prepare the model and the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bba014b1-b340-4954-97ce-dabd99b96494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709a8c22b8b14775b156ba12c6a1cdab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    config=model_config,\n",
    "    device_map='auto',\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd249b8-b77d-42f4-9239-69fbbff8721a",
   "metadata": {},
   "source": [
    "## Define the query pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "db693799-22a0-4e9e-ad7a-1f0f8f37dac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare pipeline: 0.0 sec.\n"
     ]
    }
   ],
   "source": [
    "time_1 = time()\n",
    "query_pipeline = transformers.pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        torch_dtype=torch.float16,\n",
    "        device_map=\"auto\",)\n",
    "time_2 = time()\n",
    "print(f\"Prepare pipeline: {round(time_2-time_1, 3)} sec.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae06aa30-5360-4f02-a8aa-a9b83553e078",
   "metadata": {},
   "source": [
    "## We define a function for testing the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b5d29018-df00-400b-aaac-945d527e3785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(tokenizer, pipeline, prompt_to_test):\n",
    "    \"\"\"\n",
    "    Perform a query\n",
    "    print the result\n",
    "    Args:\n",
    "        tokenizer: the tokenizer\n",
    "        pipeline: the pipeline\n",
    "        prompt_to_test: the prompt\n",
    "    Returns\n",
    "        None\n",
    "    \"\"\"\n",
    "    # adapted from https://huggingface.co/blog/llama2#using-transformers\n",
    "    time_1 = time()\n",
    "    sequences = pipeline(\n",
    "        prompt_to_test,\n",
    "        do_sample=True,\n",
    "        top_k=10,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        max_length=200,)\n",
    "    time_2 = time()\n",
    "    print(f\"Test inference: {round(time_2-time_1, 3)} sec.\")\n",
    "    for seq in sequences:\n",
    "        print(f\"Result: {seq['generated_text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8671089-757f-44fa-a127-d14cd61f3845",
   "metadata": {},
   "source": [
    "### Test the query pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b765f045-eaaa-4b34-8b8f-ce07cf67b2e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test inference: 24.086 sec.\n",
      "Result: Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\n",
      "The State of the Union address is an annual speech delivered by the President of the United States to Congress, in which the President reports on the current state of the union and outlines policy goals and legislative proposals for the upcoming year.\n"
     ]
    }
   ],
   "source": [
    "test_model(tokenizer,\n",
    "           query_pipeline,\n",
    "           \"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710e086-1b2b-430f-8b74-b113ef5666a9",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125bbff1-324d-4130-bb32-c48182306138",
   "metadata": {},
   "source": [
    "### Check the model with a HuggingFace pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e1519033-bd6b-41ee-ab4f-c9e9a18dfc9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe State of the Union address is an annual speech delivered by the President of the United States to a joint session of Congress, typically in January, in which the President reports on the current state of the union and outlines legislative priorities for the upcoming year.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = HuggingFacePipeline(pipeline=query_pipeline)\n",
    "# checking again that everything is working fine\n",
    "llm.invoke(input=\"Please explain what is the State of the Union address. Give just a definition. Keep it in 100 words.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202f15ab-0119-4948-bded-0a994cdbf57f",
   "metadata": {},
   "source": [
    "## Ingestion of data using Text loder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dac0b2c8-456b-4d5a-bda8-727ad7eb7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"biden-sotu-2023-planned-official.txt\", encoding=\"utf8\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "924a87be-9877-439c-acda-0057d4f11f8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ee98f18c-a92b-47ad-956b-36c5215806d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mr. Speaker. Madam Vice President. Our First Lady and Second Gentleman. Members of Congress and the Cabinet. Leaders of our military. Mr. Chief Justice, Associate Justices, and retired Justices of the Supreme Court. And you, my fellow Americans. I start tonight by congratulating the members of the 118th Congress and the new Speaker of the House, Kevin McCarthy. Mr. Speaker, I look forward to working together. I also want to congratulate the new leader of the House Democrats and the first Black H'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].page_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d77f3aa-0041-4ed4-aca0-d9dfa82e3217",
   "metadata": {},
   "source": [
    "## Split data in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d071e414-9df7-437b-b830-fe167a7e7ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "all_splits = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d367cd0b-59ae-4ef6-816b-1718a1fe3a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9aff96f1-3d24-4910-9d22-df4db863a928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Mr. Speaker. Madam Vice President. Our First Lady and Second Gentleman. Members of Congress and the Cabinet. Leaders of our military. Mr. Chief Justice, Associate Justices, and retired Justices of the Supreme Court. And you, my fellow Americans. I start tonight by congratulating the members of the 118th Congress and the new Speaker of the House, Kevin McCarthy. Mr. Speaker, I look forward to working together. I also want to congratulate the new leader of the House Democrats and the first Black House Minority Leader in history, Hakeem Jeffries. Congratulations to the longest serving Senate Leader in history, Mitch McConnell. And congratulations to Chuck Schumer for another term as Senate Majority Leader, this time with an even bigger majority. And I want to give special recognition to someone who I think will be considered the greatest Speaker in the history of this country, Nancy Pelosi. The story of America is a story of progress and resilience. Of always moving forward. Of never', metadata={'source': 'biden-sotu-2023-planned-official.txt'})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_splits[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0eab148-443b-4089-ad83-216ee98745a9",
   "metadata": {},
   "source": [
    "## Creating Embeddings and Storing in Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8788e80-88b0-4f94-a1ee-1eb669084dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "# model_kwargs = {\"device\": \"cuda\"}\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ffe6ffa9-81c6-4ab5-b9dc-66f6be7880ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=all_splits, embedding=embeddings, persist_directory=\"chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1963a9c2-5ec9-49b3-baa8-f4989c225c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.chroma.Chroma at 0x7f8cde0835d0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d4444-5980-46c6-9395-88898f13a12f",
   "metadata": {},
   "source": [
    "## Initialize chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6f2913f9-f11d-49c8-8ebb-931e62b44a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6f295ff2-2739-4c23-b275-b61725f68ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RetrievalQA(verbose=True, combine_documents_chain=StuffDocumentsChain(llm_chain=LLMChain(prompt=PromptTemplate(input_variables=['context', 'question'], template=\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n{context}\\n\\nQuestion: {question}\\nHelpful Answer:\"), llm=HuggingFacePipeline(pipeline=<transformers.pipelines.text_generation.TextGenerationPipeline object at 0x7f8e53382dd0>)), document_variable_name='context'), retriever=VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7f8cde0835d0>))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce627e25-1740-4f94-bcd3-a96f8d2a1c3c",
   "metadata": {},
   "source": [
    "## Test the Retrieval-Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0e227808-7bc2-405e-9bed-918e29942485",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rag(qa, query):\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    time_1 = time()\n",
    "    result = qa.invoke(query)\n",
    "    time_2 = time()\n",
    "    print(f\"Inference time: {round(time_2-time_1, 3)} sec.\")\n",
    "    print(\"\\nResult: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "eb30b394-badf-4675-aad9-3087d4b1802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Inference time: 55.295 sec.\n",
      "\n",
      "Result:  {'query': 'What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.', 'result': \" The main topics in the State of the Union in 2023 were the strength of the American people, the state of the union, and the competition with China. The President emphasized the resilience and optimism of the American people and highlighted the nation's economic and military strength. He also addressed the challenge of China's growing power and the need to protect American sovereignty.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"What were the main topics in the State of the Union in 2023? Summarize. Keep it under 200 words.\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d17f5dab-0ad2-4927-a693-db858bccd10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the nation economic status? Summarize. Keep it under 200 words.\n",
      "\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Inference time: 86.23 sec.\n",
      "\n",
      "Result:  {'query': 'What is the nation economic status? Summarize. Keep it under 200 words.', 'result': \" According to the president, the economy has created a record 12 million new jobs in two years, more than any president has ever created in four years. This indicates a strong economy with job growth, which is a positive sign for the nation's economic status. Additionally, the president notes that COVID no longer controls their lives, suggesting that the nation has made significant progress in recovering from the economic impact of the pandemic. However, the president also acknowledges that the nation's democracy faced its greatest threat since the Civil War, which could indicate ongoing challenges for the nation's political stability and economic resilience. Overall, the president's message suggests that the nation's economic status is strong, but there may be ongoing challenges that need to be addressed.\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the nation economic status? Summarize. Keep it under 200 words.\"\n",
    "test_rag(qa, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e1f0f2-a54d-4ab3-b0c9-93806b15bbae",
   "metadata": {},
   "source": [
    "## Document sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9ec4db5b-a952-4cbe-b4a0-be70e45bde39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the nation economic status? Summarize. Keep it under 200 words.\n",
      "Retrieved documents: 4\n",
      "Source:  biden-sotu-2023-planned-official.txt\n",
      "Text:  forward. Of never giving up. A story that is unique among all nations. We are the only country that has emerged from every crisis stronger than when we entered it. That is what we are doing again. Two years ago, our economy was reeling. As I stand here tonight, we have created a record 12 million new jobs, more jobs created in two years than any president has ever created in four years. Two years ago, COVID had shut down our businesses, closed our schools, and robbed us of so much. Today, COVID no longer controls our lives. And two years ago, our democracy faced its greatest threat since the Civil War. Today, though bruised, our democracy remains unbowed and unbroken. As we gather here tonight, we are writing the next chapter in the great American story, a story of progress and resilience. When world leaders ask me to define America, I define our country in one word: Possibilities. You know, we’re often told that Democrats and Republicans can’t work together. But over these past two \n",
      "\n",
      "Source:  biden-sotu-2023-planned-official.txt\n",
      "Text:  forward. Of never giving up. A story that is unique among all nations. We are the only country that has emerged from every crisis stronger than when we entered it. That is what we are doing again. Two years ago, our economy was reeling. As I stand here tonight, we have created a record 12 million new jobs, more jobs created in two years than any president has ever created in four years. Two years ago, COVID had shut down our businesses, closed our schools, and robbed us of so much. Today, COVID no longer controls our lives. And two years ago, our democracy faced its greatest threat since the Civil War. Today, though bruised, our democracy remains unbowed and unbroken. As we gather here tonight, we are writing the next chapter in the great American story, a story of progress and resilience. When world leaders ask me to define America, I define our country in one word: Possibilities. You know, we’re often told that Democrats and Republicans can’t work together. But over these past two \n",
      "\n",
      "Source:  biden-sotu-2023-planned-official.txt\n",
      "Text:  on the state of the union. And here is my report. Because the soul of this nation is strong, because the backbone of this nation is strong, because the people of this nation are strong, the State of the Union is strong. As I stand here tonight, I have never been more optimistic about the future of America. We just have to remember who we are. We are the United States of America and there is nothing, nothingbeyond our capacity if we do it together. May God bless you all. May God protect our troops. \n",
      "\n",
      "Source:  biden-sotu-2023-planned-official.txt\n",
      "Text:  on the state of the union. And here is my report. Because the soul of this nation is strong, because the backbone of this nation is strong, because the people of this nation are strong, the State of the Union is strong. As I stand here tonight, I have never been more optimistic about the future of America. We just have to remember who we are. We are the United States of America and there is nothing, nothingbeyond our capacity if we do it together. May God bless you all. May God protect our troops. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = vectordb.similarity_search(query)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Retrieved documents: {len(docs)}\")\n",
    "for doc in docs:\n",
    "    doc_details = doc.to_json()['kwargs']\n",
    "    print(\"Source: \", doc_details['metadata']['source'])\n",
    "    print(\"Text: \", doc_details['page_content'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217c6ea5-cf32-47f7-867b-3ad7a7de8cac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
